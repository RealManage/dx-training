# RealManage AI Skills Development Program

## Executive Summary

AI fluency is becoming an expected skill for all RealManage team members. This program provides structured training, peer support, and hands-on practice to help everyone develop confidence with AI-assisted workflows.

**This isn't about replacing you - it's about giving you powerful new tools.**

## Why AI Fluency Matters

AI-assisted development helps us:

- **Ship faster** - Reduce time spent on boilerplate and repetitive tasks
- **Catch more bugs** - AI reviews complement human code review
- **Focus on creativity** - Spend more time on interesting problems, less on tedious work
- **Stay competitive** - AI fluency is rapidly becoming an industry standard skill

Our analytics showed some team members are already getting significant value from AI tools, while others haven't had time to explore them. This program ensures everyone has the opportunity to build these skills.

## Goals

1. **Universal AI fluency** - Everyone comfortable using AI in their daily work
2. **Role-appropriate skills** - Developers, QA, and PMs each learn relevant workflows
3. **Peer support network** - Early Adopters on each team to help teammates
4. **Measurable impact** - Track whether AI assistance actually improves our outcomes

## Training Approach

See **[Training Schedule](training-schedule.md)** for session details, groups, and logistics.

**Why group-based?** Peer learning, protected time, real-time support, shared experience.

## Role-Specific Tracks

| Track | Focus Areas |
| ----- | ----------- |
| **Developer** | Code review, TDD, refactoring, debugging |
| **QA** | Test case generation, bug analysis, test automation |
| **PM** | User stories, acceptance criteria, spec writing |

**Developers:** Since we don't have dedicated QA, the QA track is recommended after completing your developer certification.

See [Certification Tracks](../certification/README.md) for details.

## Support for Different Paces

**We know not everyone learns at the same speed, and that's okay.**

| If you're... | Here's what we offer |
| ------------ | -------------------- |
| Struggling | 1:1 coaching sessions with trainers |
| Behind schedule | Extended timeline (just let us know) |
| Experienced already | Move faster, help teammates along the way |
| Hitting blockers | Early Adopters on your team to help |

**There's no penalty for needing more time.** The goal is competence, not speed.

## Peer Support

### Early Adopters â†’ Peer Support

**Early Adopters** (Group 1) complete training first and naturally become informal resources for later groups:

- **Who they are:** Team members who volunteered to go first
- **What they do:** Answer questions, pair with teammates, share tips in #ai-exchange
- **What they don't do:** Grade your work, report to management, judge your pace

Some early adopters gravitate toward helping others more than others - and that's fine. The DX Team remains the primary support resource for everyone.

## Code Review Artifacts

As teams build fluency, we'll introduce AI-assisted code review artifacts:

- **Purpose:** Capture learnings and ensure AI review actually happened
- **Format:** Simple markdown document committed with MRs
- **Flexibility:** Lightweight format available for trivial changes

**Why artifacts?** They create a knowledge base of patterns, catch issues early, and help us measure whether AI assistance improves code quality.

See [Code Review Standard](../standards/ai-code-review-standard.md) for templates.

## This Won't Affect Your Job (Really)

Let's address the elephant in the room:

**AI tools don't replace developers, QA engineers, or PMs. They amplify what you already do.**

- AI can generate boilerplate, but it can't understand your domain knowledge
- AI can suggest test cases, but it can't determine what's actually important to test
- AI can draft user stories, but it can't talk to customers or make product decisions

The teams getting the most value from AI are the ones with strong humans guiding it. That's you.

## Timeline

| Phase | Milestone |
| ----- | --------- |
| Week 0 | Program announced, course materials available |
| Weeks 1-9 | Group 1 (Early Adopters) training |
| Week 9 | Early Adopters complete, begin supporting teammates |
| Week 10 | Demo Day #1 - Real examples from Early Adopters |
| Weeks 10-18 | Groups 2A/2B/2C (Main Wave) training |
| Week 18 | Demo Day #2 - Main Wave completion |
| Weeks 19-27 | Group 3 (Remaining team members) training |
| Week 27 | Demo Day #3 - Celebrate full completion |
| Week 28+ | Artifact adoption ramps up gradually |

## Success Metrics

We're measuring outcomes, not just activity:

### Outcome Metrics (What Actually Matters)

| Metric | What We're Measuring |
| ------ | -------------------- |
| Cycle time | Are MRs merging faster? |
| Bug rate | Are we catching more issues before production? |
| Satisfaction | Do team members feel more productive? |
| Voluntary usage | Are people choosing to use AI even when not required? |

### Activity Metrics (Progress Tracking)

| Metric | Target |
| ------ | ------ |
| Training completion | 100% |
| Code review artifacts | 80%+ of eligible MRs |
| Demo Day participation | 50%+ per session |

## Support Resources

See [Getting Help](../../resources/getting-help.md) for all support channels.

---

## Related Documents

| Document | Purpose |
| -------- | ------- |
| [Training Schedule](training-schedule.md) | Session format, groups, expectations |
| [Communication Plan](communication-plan.md) | Announcements, templates, messaging |
| [Certification Overview](../certification/README.md) | Requirements, submission, FAQ |
| [Code Review Standard](../standards/ai-code-review-standard.md) | Artifact templates |
| [Skeptics FAQ](../faq/skeptics-faq.md) | Honest answers to common concerns |

---

## Approval

| Role | Name | Status |
| ---- | ---- | ------ |
| CTO | | Pending |
| VP Engineering | | Pending |
| DX Lead | | Author |
